{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecd4734f",
   "metadata": {},
   "source": [
    "# Grassmann Differential Evolution - An Experiment\n",
    "\n",
    "What if we represent a point in DE using subspaces instead of vectors? Let's try!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc932707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fd834e",
   "metadata": {},
   "source": [
    "I want to solve PCA as the objective function, that is:\n",
    "\n",
    "$$\n",
    "    f(\\textbf{X}) = \\min_{\\textbf{Q}} \\text{tr}(\\textbf{Q}^T\\textbf{X}\\textbf{Q})\n",
    "$$\n",
    "s.t\n",
    "$$\n",
    "    \\textbf{Q} \\in \\text{Gr}(k, n)\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$\\textbf{X}$ is an auto correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25d3d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def objective_function(X: torch.Tensor, Q: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Objective function to minimize.\"\"\"\n",
    "    return torch.einsum(\"...ii\", Q.mH @ X @ Q) / Q.shape[-1]\n",
    "\n",
    "def auto_correlation_matrix(data: torch.Tensor) -> torch.Tensor:\n",
    "    _, n = data.shape\n",
    "    data = (data - data.min()) / (data.max() - data.min())\n",
    "    X = torch.matmul(data.mH, data)\n",
    "    X /= (n - 1)\n",
    "    return X\n",
    "\n",
    "def show_matrix(X: torch.Tensor | list[torch.Tensor], title: str) -> None:\n",
    "    if isinstance(X, torch.Tensor):\n",
    "        assert X.dim() == 2\n",
    "        plt.imshow(X.cpu().numpy(), cmap=\"gray\")\n",
    "        plt.colorbar()\n",
    "        plt.title(title)\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    elif isinstance(X, list):\n",
    "        n = len(X)\n",
    "        fig, axes = plt.subplots(1, n, figsize=(n * 2, 2))\n",
    "        for i in range(n):\n",
    "            axes[i].imshow(X[i].cpu().numpy(), cmap=\"gray\")\n",
    "            axes[i].axis(\"off\")\n",
    "        plt.title(title)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "mnist = MNIST(\"~/Datasets\", download=True, train=False)\n",
    "data = mnist.data.view(mnist.data.shape[0], -1).float().to(device)\n",
    "\n",
    "X = auto_correlation_matrix(data)\n",
    "n_components = 5\n",
    "\n",
    "show_matrix(X, \"Auto-correlation matrix of MNIST training data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3715e97a",
   "metadata": {},
   "source": [
    "### First let's compute PCA using an eigen-decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabfd901",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues, eigenvectors = torch.linalg.eig(X)\n",
    "\n",
    "#  Eigenvalues are supposed to be positive reals.\n",
    "# This condtion may fail only if there are numerical errors.\n",
    "# We can ignore the torch warning here about casting complex -> real\n",
    "if torch.max(torch.imag(eigenvalues)) > 1.e-5:\n",
    "    raise (AssertionError(\n",
    "        \"Eigenvalues of autocorrelation matrix are supposed to be real, \"\n",
    "        f\"but has imaginary part {torch.max(torch.imag(eigenvalues))}\"))\n",
    "\n",
    "eigenvalues = torch.real(eigenvalues)\n",
    "eigenvectors = torch.real(eigenvectors)\n",
    "\n",
    "squared_eigenvalues = torch.square(eigenvalues)\n",
    "sorted_indices = torch.argsort(squared_eigenvalues, descending=True)\n",
    "squared_eigenvalues.sort(descending=True)\n",
    "\n",
    "Q1 = eigenvectors[:, sorted_indices][:, :n_components]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708ab1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = objective_function(X, Q1)\n",
    "print(f\"Objective function value: {o.item():.6f}\")\n",
    "\n",
    "show_matrix(\n",
    "    [Q1[:, i].view(28, 28) for i in range(n_components)],\n",
    "    f\"Principal Components of MNIST data (Top {n_components})\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a5d03d",
   "metadata": {},
   "source": [
    "### Now let's try calculating PCA using differential evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373087b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "from subspyces.core import VectorSpace\n",
    "from subspyces.generators import IdentityGenerator\n",
    "from subspyces.transform import PCATransform\n",
    "\n",
    "mnist_train = MNIST(\"~/Datasets\", download=True, train=True,\n",
    "                    transform=T.Compose([T.ToTensor(), torch.flatten]))\n",
    "\n",
    "generator = IdentityGenerator()\n",
    "train_vector_spaces = generator.generate(mnist_train, batch_size=512)\n",
    "pca_transform = PCATransform(n_components=5)\n",
    "pca_vector_subspaces = dict()\n",
    "\n",
    "for vector_space in train_vector_spaces.values():\n",
    "    pca_vector_subspace = pca_transform.transform(vector_space)\n",
    "    pca_vector_subspaces[pca_vector_subspace.label] = pca_vector_subspace\n",
    "\n",
    "subspace_1 = [vs.view(28, 28) for vs in pca_vector_subspaces[1]._data]\n",
    "subspace_2 = [vs.view(28, 28) for vs in pca_vector_subspaces[2]._data]\n",
    "\n",
    "show_matrix(subspace_1, \"Top 5 PCA components from Subspyces - Digit 1\")\n",
    "show_matrix(subspace_2, \"Top 5 PCA components from Subspyces - Digit 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f31b64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_difference_pc_subspace(*subspaces: torch.Tensor) -> torch.Tensor:\n",
    "    orthogonal_projections = []\n",
    "    for s in subspaces:\n",
    "        assert s.dim() == 2, \"Input subspaces must be 2D tensors\"\n",
    "        orthogonal_projections.append(s @ s.mH)\n",
    "\n",
    "    sum = torch.stack(orthogonal_projections).sum(dim=0)\n",
    "\n",
    "    eigenvalues, eigenvectors = torch.linalg.eigh(sum)\n",
    "    eigenvalues = torch.real(eigenvalues)\n",
    "    eigenvectors = torch.real(eigenvectors)\n",
    "    \n",
    "    sorted_indices = torch.argsort(torch.abs(eigenvalues), descending=True)\n",
    "    eigenvalues = eigenvalues[sorted_indices]\n",
    "    eigenvectors = eigenvectors[:, sorted_indices]\n",
    "    first_less_than_1 = torch.where(eigenvalues < 1.0)[0][0]\n",
    "\n",
    "    difference_subspace = eigenvectors[:, first_less_than_1:first_less_than_1 + subspaces[0].shape[1]]\n",
    "    principal_component_subspace = eigenvectors[:, :first_less_than_1]\n",
    "\n",
    "    return difference_subspace, principal_component_subspace\n",
    "\n",
    "diff, principal = compute_difference_pc_subspace(\n",
    "    pca_vector_subspaces[1]._data.T,\n",
    "    pca_vector_subspaces[2]._data.T,\n",
    "    pca_vector_subspaces[3]._data.T,\n",
    ")\n",
    "\n",
    "show_matrix(\n",
    "    [diff[:, i].view(28, 28) for i in range(n_components)],\n",
    "    \"Difference Subspace between Digit 1 and Digit 2 PCA components\",\n",
    ")\n",
    "show_matrix(\n",
    "    [principal[:, i].view(28, 28) for i in range(n_components)],\n",
    "    \"Difference Subspace between Digit 1 and Digit 2 PCA components\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3573e3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "population_size = 50\n",
    "subspace_dim = (X.shape[0], n_components)\n",
    "epochs = 1000\n",
    "\n",
    "\n",
    "# Initialize population and enforce orthonormality using QR decomposition\n",
    "population = torch.randn(population_size, *subspace_dim, device=device)\n",
    "population, _ = torch.linalg.qr(population)\n",
    "print(\"Initialized population with shape\", population.shape)\n",
    "\n",
    "best_fitness_history = []\n",
    "mean_fitness_history = []\n",
    "for epoch in (pbar := tqdm(range(epochs), desc=\"Epochs\")):\n",
    "    # Evaluate objective function for each individual\n",
    "    fitness = objective_function(X, population)\n",
    "\n",
    "    for i in range(population_size):\n",
    "        # pick three *distinct* indices not equal i\n",
    "        idxs = [idx for idx in range(population_size) if idx != i]\n",
    "        samples = torch.randperm(len(idxs))[:3]\n",
    "        x1, x2, x3 = population[samples[0]], population[samples[1]], population[samples[2]]\n",
    "\n",
    "        # Mutation\n",
    "        mutant = x1 + generate_difference_subspace(x2, x3)\n",
    "        mutant, _ = torch.linalg.qr(mutant)\n",
    "\n",
    "        # Selection\n",
    "        f_trial = objective_function(X, mutant)\n",
    "        if f_trial > fitness[i]:\n",
    "            population[i] = mutant\n",
    "            fitness[i] = f_trial\n",
    "\n",
    "    # Record best and mean fitness\n",
    "    best_idx = torch.argmax(fitness)\n",
    "    best_fitness_history.append(fitness[best_idx])\n",
    "    mean_fitness_history.append(torch.mean(fitness))\n",
    "    pbar.set_postfix(best_fitness=fitness[best_idx].item(), mean_fitness=mean_fitness_history[-1].item())\n",
    "\n",
    "# Get the best individual from the final population\n",
    "best_idx = torch.argmax(fitness)\n",
    "Q2 = population[best_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea396398",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = objective_function(X, Q2)\n",
    "print(f\"Objective function value: {o.item():.6f}\")\n",
    "\n",
    "show_matrix(\n",
    "    [Q2[:, i].view(28, 28) for i in range(n_components)],\n",
    "    f\"Principal Components of MNIST data (Top {n_components})\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
